{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"Datasets/CoffeeMachineData.csv\":{\n",
    "            \"numerical\":['Capacity (Liters)','Power Output (kW)','Price (USD)','Brew Time (Minutes)','Weight (kg)'],\n",
    "            \"categorical\":['Machine Name','Type','Ease of Use','Brew Quality'],\n",
    "        },\n",
    "    \"Datasets/Fruit_Veg_Processing_Machines.csv\": {\n",
    "            \"numerical\":['Speed (kg/hr)', 'Power Input (kW)', 'Efficiency (%)','Price (USD)'],\n",
    "            \"categorical\":['Machine Name', 'MType', 'MachineMaterial','Manufacturer'],\n",
    "        },\n",
    "    \"Datasets/grain_machinery_data.csv\":{\n",
    "            \"numerical\":['Capacity (tons/hour)', 'Power Output (kW)', 'Price (USD)'],\n",
    "            \"categorical\":['Grain', 'Machine Name', 'Grain Manufacturer'],\n",
    "        },\n",
    "    \"Datasets/Ice_Cream_Makers.csv\":{\n",
    "            \"numerical\":['Noise Levels','Power(W)','Price (USD)'],\n",
    "            \"categorical\":['Machine Name', 'Capacity', 'Batch Output'],\n",
    "        },\n",
    "    \"Datasets/juice_makers.csv\":\n",
    "        {\n",
    "            \"numerical\":[\n",
    "                        'Motor Power (W)', 'Juicing Speed (RPM)', 'Noise Level (dB)',\n",
    "                        'Customer Rating', 'Number of Reviews', 'Price (USD)',\n",
    "                        ],\n",
    "            \"categorical\":['Machine Name', 'Material','Type of Juicer'],\n",
    "        },    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"Datasets/CoffeeMachineData.csv\",\n",
    "            \"Datasets/Fruit_Veg_Processing_Machines.csv\",\n",
    "            \"Datasets/grain_machinery_data.csv\",\n",
    "            \"Datasets/Ice_Cream_Makers.csv\",\n",
    "            \"Datasets/juice_makers.csv\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_detect(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "def calc_combined_feature_matrix(file_path, user_input):\n",
    "    df = pd.read_csv(file_path, encoding=encoding_detect(file_path))   \n",
    "    categorical_cols = features[file_path][\"categorical\"]\n",
    "    numerical_cols = features[file_path][\"numerical\"] \n",
    "    \n",
    "    df[categorical_cols] = df[categorical_cols].fillna('')\n",
    "    for col in numerical_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Numerical column '{col}' is missing in the dataset.\")\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    \n",
    "    df['combined_features'] = df[categorical_cols].apply(lambda x: ' '.join(x).lower(), axis=1)\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    text_features = tfidf.fit_transform(df['combined_features'])  \n",
    "    combined_features_matrix = np.hstack([\n",
    "        text_features.toarray(), \n",
    "        df[numerical_cols].values\n",
    "    ])\n",
    "    return combined_features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findr(file_path, user_input, findr_col, n_recom = 20): \n",
    "    df = pd.read_csv(file_path, encoding=encoding_detect(file_path))\n",
    "    combined_features_matrix = calc_combined_feature_matrix(file_path, user_input)\n",
    "    cosine_sim = cosine_similarity(combined_features_matrix)\n",
    "    # print(\"Cosine Shape: \",cosine_sim.shape)\n",
    "    # print(\"Cosine Similarity: \\n\",cosine_sim)\n",
    "    column = findr_col\n",
    "    matching_rows = df[df[column].str.contains(user_input, case=False, na=False, regex=False)]\n",
    "    if matching_rows.empty:\n",
    "        return f\"Machine '{user_input}' not found in the dataset.\"\n",
    "    \n",
    "    idx = matching_rows.index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    print(\"sim score shape: \",len(sim_scores))\n",
    "    print(\"sim scores: \\n\",sim_scores)\n",
    "    sim_indices = [i[0] for i in sim_scores[1:n_recom+1]]\n",
    "    \n",
    "    df = pd.read_csv(file_path,encoding=encoding_detect(file_path))\n",
    "    data = df.iloc[sim_indices]\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input = 'drip'\n",
    "# findr_col = 'Type'\n",
    "# num_recommendations = 50\n",
    "# recommendations = findr(datasets[0], user_input, findr_col,n_recom=num_recommendations) # incomplete - take datasets index from \n",
    "# recommendations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drip_recommendations = recommendations[recommendations['Type'].str.contains('Drip', case = False, na = False)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(recommendations, drip_recommendations):\n",
    "    precision = len(drip_recommendations) / len(recommendations)\n",
    "    return precision\n",
    "\n",
    "def coverage(recommendations, dataset_path): \n",
    "    df = pd.read_csv(dataset_path, encoding=encoding_detect(dataset_path))\n",
    "    total_unique_items = len(df['Machine Name'].unique())\n",
    "    unique_items_in_recommendations = len(recommendations['Machine Name'].unique())\n",
    "    coverage = unique_items_in_recommendations / total_unique_items\n",
    "    return coverage\n",
    "\n",
    "# def divesity_score(recommendations, file_path, user_input):\n",
    "#     n = len(recommendations)\n",
    "#     combined_features_matrix = calc_combined_feature_matrix(file_path, user_input)\n",
    "#     recommended_indices = recommendations.index\n",
    "#     recommended_features = combined_features_matrix[recommended_indices]\n",
    "#     pairwise_similarities = cosine_similarity(recommended_features)\n",
    "#     total_pairs = n * (n - 1) / 2\n",
    "#     average_similarity = (np.sum(pairwise_similarities) / total_pairs) if total_pairs > 0 else 0\n",
    "#     diversity_score = 1 - average_similarity\n",
    "#     return diversity_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(dataset_path, user_input, findr_col, n_recom=20):\n",
    "    if dataset_path not in features:\n",
    "        raise ValueError(f\"Dataset {dataset_path} not found in features dictionary\")\n",
    "    \n",
    "    categorical_cols = features[dataset_path][\"categorical\"]\n",
    "    if findr_col not in categorical_cols:\n",
    "        raise ValueError(f\"Search column {findr_col} not found in categorical columns for {dataset_path}\")\n",
    "    \n",
    "    # Get recommendations\n",
    "    recommendations = findr(dataset_path, user_input, findr_col, n_recom)\n",
    "    \n",
    "    if isinstance(recommendations, str):  # Error message returned\n",
    "        return {\n",
    "            \"error\": recommendations,\n",
    "            \"metrics\": None\n",
    "        }\n",
    "    \n",
    "    # 1. Precision\n",
    "    matching_recommendations = recommendations[recommendations[findr_col].str.contains(user_input, case=False, na=False, regex=False)]\n",
    "    prec = precision(recommendations, matching_recommendations)\n",
    "    \n",
    "    # 2. Coverage\n",
    "    cov = coverage(recommendations, dataset_path)\n",
    "    \n",
    "    # 3. Diversity\n",
    "    # div = divesity_score(recommendations, dataset_path, user_input)\n",
    "    \n",
    "    results = {\n",
    "        \"metrics\": {\n",
    "            \"precision\": prec,\n",
    "            \"coverage\": cov,\n",
    "            # \"diversity\": div\n",
    "        },\n",
    "        \"details\": {\n",
    "            \"dataset\": dataset_path,\n",
    "            \"search_column\": findr_col,\n",
    "            \"user_input\": user_input,\n",
    "            \"total_recommendations\": len(recommendations),\n",
    "            \"matching_recommendations\": len(matching_recommendations),\n",
    "            \"unique_recommendations\": len(recommendations['Machine Name'].unique()),\n",
    "            \"total_catalog_items\": len(pd.read_csv(dataset_path, encoding=encoding_detect(dataset_path))['Machine Name'].unique())\n",
    "        }\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_recommendations():\n",
    "    test_cases = [\n",
    "        # Coffee machines\n",
    "        {\"dataset\": datasets[0], \"input\": \"drip\", \"col\": \"Type\"},\n",
    "        {\"dataset\": datasets[0], \"input\": \"espresso\", \"col\": \"Type\"},\n",
    "        \n",
    "        # Fruit/Veg equipment\n",
    "        {\"dataset\": datasets[1], \"input\": \"juicer\", \"col\": \"MType\"},\n",
    "        \n",
    "        # Grain processing\n",
    "        {\"dataset\": datasets[2], \"input\": \"wheat\", \"col\": \"Grain\"},\n",
    "        \n",
    "        # Ice cream machines\n",
    "        {\"dataset\": datasets[3], \"input\": \"commercial\", \"col\": \"Machine Name\"},\n",
    "        \n",
    "        # Juice machines\n",
    "        {\"dataset\": datasets[4], \"input\": \"centrifugal\", \"col\": \"Type of Juicer\"}\n",
    "    ]\n",
    "    \n",
    "    for case in test_cases:\n",
    "        print(f\"\\nTesting {case['dataset']} with input '{case['input']}' in column '{case['col']}'\")\n",
    "        try:\n",
    "            result = evaluate_recommendations(case['dataset'], case['input'], case['col'])\n",
    "            if result['metrics']:\n",
    "                print(f\"Precision: {result['metrics']['precision']:.4f}\")\n",
    "                print(f\"Coverage: {result['metrics']['coverage']:.4f}\")\n",
    "                # print(f\"Diversity: {result['metrics']['diversity']:.4f}\")\n",
    "                print(f\"Total recommendations: {result['details']['total_recommendations']}\")\n",
    "            else:\n",
    "                print(f\"Error: {result['error']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim score shape:  109\n",
      "sim scores: \n",
      " [(2, np.float64(0.9999999999999998)), (87, np.float64(0.43349882610276314)), (6, np.float64(0.3976334958777079)), (106, np.float64(0.39106761446240224)), (30, np.float64(0.36381577816501975)), (102, np.float64(0.35684076186800007)), (103, np.float64(0.3534838240887347)), (105, np.float64(0.34806855673007686)), (63, np.float64(0.34456088178495026)), (66, np.float64(0.33306432103885236)), (101, np.float64(0.33226157154543234)), (86, np.float64(0.32481420222576096)), (53, np.float64(0.3223295514860177)), (20, np.float64(0.32211166327852725)), (19, np.float64(0.314454336568684)), (82, np.float64(0.3124425012433271)), (81, np.float64(0.31107303592094926)), (96, np.float64(0.2978507846063059)), (90, np.float64(0.2942908184737521)), (21, np.float64(0.2932148511872739)), (95, np.float64(0.2914756717630736)), (69, np.float64(0.28956856359440775)), (92, np.float64(0.2890230358258039)), (93, np.float64(0.2885356169876134)), (60, np.float64(0.28699894421560246)), (3, np.float64(0.28452468842872763)), (12, np.float64(0.28448319705494396)), (1, np.float64(0.2792701020631159)), (70, np.float64(0.27802964017742055)), (61, np.float64(0.27784775950956514)), (14, np.float64(0.2777883652073784)), (15, np.float64(0.2776878202048497)), (94, np.float64(0.2748153633939135)), (43, np.float64(0.27351464194866026)), (72, np.float64(0.2713946701860124)), (64, np.float64(0.27122048781538394)), (17, np.float64(0.27027331575534197)), (51, np.float64(0.2695482117665637)), (26, np.float64(0.26651737469161024)), (25, np.float64(0.26587031345678513)), (85, np.float64(0.26466476573564696)), (104, np.float64(0.26389127593310097)), (33, np.float64(0.26212309647460064)), (42, np.float64(0.2614044706493144)), (52, np.float64(0.2601425637430255)), (11, np.float64(0.26005615942076715)), (107, np.float64(0.25983730677514616)), (28, np.float64(0.25943438090516335)), (37, np.float64(0.25912126681715975)), (67, np.float64(0.2573687199362136)), (84, np.float64(0.2571467189005028)), (27, np.float64(0.2560803241022527)), (56, np.float64(0.25535631622248495)), (5, np.float64(0.2550610084403371)), (83, np.float64(0.25402159016164433)), (39, np.float64(0.2539576427747371)), (35, np.float64(0.25141644834246163)), (7, np.float64(0.2510309428534566)), (44, np.float64(0.24985877274787457)), (68, np.float64(0.2487126467786861)), (4, np.float64(0.24761493085929928)), (16, np.float64(0.24531764969272896)), (54, np.float64(0.23982462884754652)), (80, np.float64(0.23820732616275336)), (65, np.float64(0.23308054647957)), (34, np.float64(0.2281345252089599)), (100, np.float64(0.2243771354348189)), (10, np.float64(0.2184835637705261)), (108, np.float64(0.21740743497138856)), (9, np.float64(0.21683530125871428)), (13, np.float64(0.21398554584225643)), (62, np.float64(0.21001744273014952)), (41, np.float64(0.2095590823401392)), (50, np.float64(0.20849847768251026)), (38, np.float64(0.2079301195294294)), (88, np.float64(0.20758708054597558)), (99, np.float64(0.20087968459191083)), (75, np.float64(0.20043679790635555)), (49, np.float64(0.19874786523359642)), (40, np.float64(0.1962135443869818)), (97, np.float64(0.19612104047354323)), (73, np.float64(0.19398529508411555)), (45, np.float64(0.19280255195734763)), (23, np.float64(0.1920745315846648)), (98, np.float64(0.19161738772209166)), (32, np.float64(0.1903070330769681)), (47, np.float64(0.18729730875617784)), (91, np.float64(0.18719864230479327)), (76, np.float64(0.18664554827852198)), (59, np.float64(0.18641571725129)), (77, np.float64(0.18503326799632241)), (31, np.float64(0.18227172031051656)), (29, np.float64(0.17415805431017162)), (57, np.float64(0.17234167023375666)), (48, np.float64(0.17181161788785185)), (71, np.float64(0.16884212431968373)), (89, np.float64(0.1658564853643961)), (58, np.float64(0.16562319008665072)), (8, np.float64(0.16474832247077503)), (74, np.float64(0.16245181203093104)), (46, np.float64(0.15411368070255982)), (79, np.float64(0.1496988429050862)), (78, np.float64(0.1475782079024532)), (24, np.float64(0.13657794087570488)), (55, np.float64(0.13184039131772504)), (18, np.float64(0.11911441369764218)), (22, np.float64(0.06495133510334733)), (36, np.float64(0.05731516932097543)), (0, np.float64(0.048907010455393196))]\n",
      "Results for Fruit/Veg Equipment - 'cutter':\n",
      "Precision: 0.5667\n",
      "Coverage: 0.2752\n",
      "\n",
      "Details:\n",
      "dataset: Datasets/CoffeeMachineData.csv\n",
      "search_column: Type\n",
      "user_input: drip\n",
      "total_recommendations: 30\n",
      "matching_recommendations: 17\n",
      "unique_recommendations: 30\n",
      "total_catalog_items: 109\n"
     ]
    }
   ],
   "source": [
    "result = evaluate_recommendations(datasets[0], \"drip\", \"Type\", n_recom=30)\n",
    "print(\"Results for Fruit/Veg Equipment - 'cutter':\")\n",
    "if result['metrics']:\n",
    "    print(f\"Precision: {result['metrics']['precision']:.4f}\")\n",
    "    print(f\"Coverage: {result['metrics']['coverage']:.4f}\")\n",
    "    print(\"\\nDetails:\")\n",
    "    for key, value in result['details'].items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre = precision(recommendations, drip_recommendations)\n",
    "# cov = coverage(recommendations, datasets[0]) \n",
    "# div = divesity_score(recommendations, datasets[0], user_input)  \n",
    "\n",
    "\n",
    "# print(f\"Precision: {pre:.4f}\")\n",
    "# print(f\"Coverage: {cov:.4f}\")\n",
    "# print(f\"Diversity: {div:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
